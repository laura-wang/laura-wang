<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiangliu Wang</title>

  <meta name="author" content="Jiangliu Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/curi.jpg">
</head>


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiangliu Wang (王江柳)</name>
              </p>
              <p>I am a research assistant professor in the Department of Mechanical and Automation Engineering at The Chinese University of Hong Kong (CUHK).     

              </p>
              <p>
              I obtained my PhD degree from <a href="http://www.cuhk.edu.hk/"> The Chinese University of Hong Kong</a> (CUHK) in 2020, where I was advised by <a href="http://ri.cuhk.edu.hk/yhliu">Prof. Yun-hui Liu</a> and funded by <a href="https://cerg1.ugc.edu.hk/hkpfs/index.html">HKPFS</a>. I obtained my bachelor degree from <a href="https://www.nju.edu.cn/"> Nanjing University</a> in 2015, where I was advised by <a href="https://www.researchgate.net/profile/Wei-Li-262">Prof. Wei Li</a>. During my PhD, I did an internship at <a href="https://ai.tencent.com/ailab/">Tencent AI Lab</a>, where I had a wonderful time working with <a href="https://jianbojiao.com/">Dr. Jianbo Jiao</a>, <a href="http://linchaobao.github.io/">Dr. Linchao Bao</a>, <a href="https://sse.cuhk.edu.cn/en/faculty/liuwei">Dr. Wei Liu</a>, and other labmates. 
              </p>
              
              <p>
              Before joining CUHK in 2023, I was a postdoctoral fellow at the Hong Kong Centre for Logistics Robotics and a visiting scholar at Tencent AI Lab and Johns Hopkins University.
              My research interets are computer vision, video understanding and their applications in meidical image analysis and surgical robots.
              </p>
              
              <p style="color: blue">
                I'm looking for motivated research assistants interetsed in surgical video analysis. If that sounds like you, feel free to reach out via email.
              </p>
              

              <p style="text-align:center">
                <a href="data/JiangliuWang-CV.pdf">CV</a> &nbsp/&nbsp
                <!--<a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=q6bsitMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!--<a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp-->
                <a href="https://github.com/laura-wang">Github</a> &nbsp/&nbsp
                <a href="mailto:jiangliuwang@link.cuhk.edu.hk">Email</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jiangliu_out_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jiangliu_out_circle.jpg" class="hoverZoomLink"></a> 
              <!JonBarron_circle.jpg>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected publications</heading>
              <p>
                The full list of my puiblication can be found in my <a href="https://scholar.google.com/citations?user=q6bsitMAAAAJ&hl=en">Google Scholar</a>
                <!--Representative papers are <span class="highlight">highlighted</span>.-->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        


                  <!---------Start one research item----------->
           <!------------------------------------------->
           <tr onmouseout="mas_stop()" onmouseover="mas_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mas_image'>
                  <img src='images/UC_Nerf.png' width="160"></div>
                <img src='images/UC_Nerf.png' width="160">
              </div>
              <script type="text/javascript">
                function mas_start() {
                  document.getElementById('mas_image').style.opacity = "1";
                }
    
                function mas_stop() {
                  document.getElementById('mas_image').style.opacity = "0";
                }
                mas_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2409.02917">
                <papertitle>UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views</papertitle>
              </a>
              <br>
              <a href="https://wrld.github.io/">Jiaxin Guo</a>,
              <strong> Jiangliu Wang </strong>,
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=hvtrnGEAAAAJ&view_op=list_works&sortby=pubdate/">Ruofeng Wei</a>,
              <a href="https://scholar.google.com.hk/citations?user=2ztThPwAAAAJ&hl=zh-CN">Di Kang</a>,
              <a href="https://www.cse.cuhk.edu.hk/~qdou/">Qi Dou</a>
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>
              <br>
              <em>Transactions on Medical Imaging</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2409.02917">pdf</a>
              /
              <a href="https://github.com/wrld/uc-nerf">code</a> 
              / 
              <a href="data/Guo-TMI.bib">bibtex</a>
              <p></p>
            </td>
          </tr>



              <!---------Start one research item----------->
           <!------------------------------------------->
          <tr onmouseout="mas_stop()" onmouseover="mas_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mas_image'>
                  <video  width=100% height=100% muted autoplay loop>
                <source src="images/merge.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <video  width=100% height=100% muted autoplay loop>
                <source src="images/merge.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
              <script type="text/javascript">
                function mas_start() {
                  document.getElementById('mas_image').style.opacity = "1";
                }
    
                function mas_stop() {
                  document.getElementById('mas_image').style.opacity = "0";
                }
                mas_stop()
              </script>
            </td>
             <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9352025">
              <papertitle>Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics</papertitle>
              </a>
              <br>
              <strong> Jiangliu Wang* </strong>,
              <a href="https://jianbojiao.com/">Jianbo Jiao*</a>,
              <a href="http://linchaobao.github.io/">Linchao Bao</a>,
              <a href="http://www.shengfenghe.com/">Shengfeng He</a>,
              <a href="https://sse.cuhk.edu.cn/en/faculty/liuwei">Wei Liu</a>,
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>
              <br>
              <em>T-PAMI</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2008.13426.pdf">pdf</a>
              / 
              <a href="https://ieeexplore.ieee.org/document/9352025">early access</a>
              /
              <a href="https://github.com/laura-wang/video_repres_sts">code</a>
              /
              <a href="data/WangTPAMI2021.bib">bibtex</a>
              <p></p>
              <p>This work is an extension of our <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Self-Supervised_Spatio-Temporal_Representation_Learning_for_Videos_by_Predicting_Motion_and_CVPR_2019_paper.pdf">CVPR 2019 paper</a>. I recommend the ablation study section. Our approach achieved decent performance after just one training epoch.  </p>
            </td>


          

           <!---------Start one research item----------->
           <!------------------------------------------->

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'>
                <video  width=100% height=100% muted autoplay loop>
                <source src="images/pace_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video>
              </div>
                <img src='images/pace_before.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }
    
                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2008.05861">
              <papertitle>Self-Supervised Video Representation Learning by Pace Prediction</papertitle>
              </a>
              <br>
              <strong>Jiangliu Wang</strong>,
              <a href="https://jianbojiao.com/">Jianbo Jiao</a>,
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>
              <br>
              <em>ECCV</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2008.05861.pdf">pdf</a>
              /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">short video</a>
              /
              <a href="https://www.youtube.com/watch?v=LCeJYkSFXSk">long video</a>
              /
              <a href="https://github.com/laura-wang/video-pace">code</a>
              / 
              <a href="data/WangECCV2020.bib">bibtex</a>
              <p></p>
              <p>This work is inspired by the observation that human visual system is sensitive to video pace, e.g., slow motion, a widely used technique in film making.</p>
            </td>
          
          <!---------Start one research item----------->
           <!------------------------------------------->
          <tr onmouseout="mas_stop()" onmouseover="mas_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mas_image'>
                  <img src='images/mas_attention.png' width="160"></div>
                <img src='images/mas_attention.png' width="160">
              </div>
              <script type="text/javascript">
                function mas_start() {
                  document.getElementById('mas_image').style.opacity = "1";
                }
    
                function mas_stop() {
                  document.getElementById('mas_image').style.opacity = "0";
                }
                mas_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Self-Supervised_Spatio-Temporal_Representation_Learning_for_Videos_by_Predicting_Motion_and_CVPR_2019_paper.html">
                <papertitle>Self-supervised spatio-temporal representation learning for videos by predicting motion and appearance statistics</papertitle>
              </a>
              <br>
              <strong> Jiangliu Wang </strong>,
              <a href="https://jianbojiao.com/">Jianbo Jiao</a>,
              <a href="http://linchaobao.github.io/">Linchao Bao</a>,
              <a href="http://www.shengfenghe.com/">Shengfeng He</a>,
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>,
              <a href="https://sse.cuhk.edu.cn/en/faculty/liuwei">Wei Liu</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Self-Supervised_Spatio-Temporal_Representation_Learning_for_Videos_by_Predicting_Motion_and_CVPR_2019_paper.pdf">pdf</a>
              /
              <a href="https://github.com/laura-wang/video_repres_mas">code</a> 
              / 
              <a href="data/WangCVPR2019.bib">bibtex</a>
              <p></p>
              <p>Neural networks are asked to predict motion and appearance statistics, including the largest motion area, largest and smallest color diversity areas. </p>
            </td>
          </tr>


           <!---------Start one research item----------->
           <!------------------------------------------->
          <tr onmouseout="nerv_stop()" onmouseover="nerv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/skeleton.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/skeleton.png' width="160">
              </div>
              <script type="text/javascript">
                function nerv_start() {
                  document.getElementById('nerv_image').style.opacity = "1";
                }
    
                function nerv_stop() {
                  document.getElementById('nerv_image').style.opacity = "0";
                }
                nerv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8672922">
                <papertitle>View-invariant human action recognition based on a 3d bio-constrained skeleton model</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=q-Qqa20AAAAJ&hl=en">Qiang Nie</a>,
              <strong>Jiangliu Wang</strong>,
              <a href="">Xin Wang</a>,
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>
              <br>
              <em>TIP</em>, 2019
              <br>
              <a href="data/NieTIP2019.pdf">pdf</a> /
              <a href="data/NieTIP2019.bib">bibtex</a>
              <p></p>
              <p>
              A 3D bio-constrained skeleton model is proposed to recover the corrupted skeletons and encode the body-level motion features into images. 
              </p>
            </td>
          </tr>


           <!---------Start one research item----------->
           <!------------------------------------------->
          <tr onmouseout="skeleton_stop()" onmouseover="skeleton_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='skeleton_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/skeleton_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/skeleton_before.png' width="160">
              </div>
              <script type="text/javascript">
                function skeleton_start() {
                  document.getElementById('skeleton_image').style.opacity = "1";
                }
                function skeleton_stop() {
                  document.getElementById('skeleton_image').style.opacity = "0";
                }
                skeleton_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8630333">
                <papertitle>Kinematics features for 3D action recognition using two-stream CNN</papertitle>
              </a>
              <br>
              
              <strong> Jiangliu Wang </strong>, 
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>
              <br>
              <!--<em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>-->
              <em>WCICA</em>, 2018
              <br>
              <a href="data/WangWCICA2018.pdf">pdf</a> /
              <a href="data/WangWCICA2018.bib">bibtex</a> 
              <p></p>
              <p>Temporal encoded kinematics features are proposed for action recognition, which compute the linear velocity and orientation displacement based on human skeleton data.</p>
            </td>
          </tr>

          <!---------Start one research item----------->
           <!------------------------------------------->
         <tr onmouseout="slam_stop()" onmouseover="slam_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='slam_image'>
                  <img src='images/slam_after.png' width="160"></div>
                <img src='images/slam_before.png' width="160">
              </div>
              <script type="text/javascript">
                function slam_start() {
                  document.getElementById('slam_image').style.opacity = "1";
                }
    
                function slam_stop() {
                  document.getElementById('slam_image').style.opacity = "0";
                }
                slam_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cje.2018.03.007">
                <papertitle>Robot Intelligence for Real World Applications
                </papertitle>
              </a>
              <br>
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>,
              <a href="https://fzheng.me/">Fan Zheng</a>,
              <a href="">Ruibin Guo</a>,
              <strong>Jiangliu Wang</strong>,
              <a href="https://scholar.google.com/citations?user=q-Qqa20AAAAJ&hl=en">Qiang Nie</a>,
              <a href="">Xin Wang</a>,
              <a href="https://www.wangzerui.com/">Zerui Wang</a>,
              <br>
              <em>Chinese Journal of Electronics</em>, 2018 
              <br>
              <a href="data/LiuCJE2018.pdf">pdf</a> /
              <a href="data/LiuCJE2018.bib">bibtex</a>
              <p></p>
              <p>This is an editor invitation paper. A brief review is presented to introduce our recent works on machine intelligence for real-world applications of robots. One technology leads to a startup company <a href="https://www.visionnav.com/">VisionNav</a>.
              </p>
            </td>
          </tr> 


           
          

          <!---------Start one research item----------->
           <!------------------------------------------->
         <tr onmouseout="child_stop()" onmouseover="child_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='child_image'>
                  <img src='images/child.png' width="160"></div>
                <img src='images/child.png' width="160">
              </div>
              <script type="text/javascript">
                function child_start() {
                  document.getElementById('child_image').style.opacity = "1";
                }
    
                function child_stop() {
                  document.getElementById('child_image').style.opacity = "0";
                }
                slam_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8665218">
                <papertitle>A child caring robot for the dangerous behavior detection based on the object recognition and human action recognitions</papertitle>
              </a>
              <br>
               <a href="https://scholar.google.com/citations?user=q-Qqa20AAAAJ&hl=en">Qiang Nie</a>,
              <a href="">Xin Wang</a>,
              <strong>Jiangliu Wang</strong>,
              <a href="http://ri.cuhk.edu.hk/yhliu">Yun-hui Liu</a>
              <br>
              <em>ROBIO</em>, 2018
              <br>
              <a href="data/NieROBIO2018.pdf">pdf</a> /
              <a href="data/NieROBIO2018.bib">bibtex</a>
              <p></p>
              <p> A caring robot is developed to detect dangerous behavior of children in the domestic environment based on action recognition and object recognition technologies.</p>
            </td>
          </tr> 
          
          <!----------------------Before PhD-------------------->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Before PhD</heading>
              <p>During my undergraduate study, I was lucky enough to work with <a href="https://www.researchgate.net/profile/Wei-Li-262">Prof. Wei Li</a> on a defense–intrusion interaction optimization problem. This work is published in a Tier 1 applied mathematics journal.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <!---------Start one research item----------->
           <!------------------------------------------->

          <tr onmouseout="phase_stop()" onmouseover="phase_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='phase_image'>
                  <img src='images/phase2.jpg' width="160"></div>
                <img src='images/phase1.jpg' width="160">
              </div>
              <script type="text/javascript">
                function phase_start() {
                  document.getElementById('phase_image').style.opacity = "1";
                }
    
                function phase_stop() {
                  document.getElementById('phase_image').style.opacity = "0";
                }
                slam_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S1007570415000970">
                <papertitle>Motion patterns and phase-transition of a defender–intruder problem and optimal interception strategy of the defender</papertitle>
              </a>
              <br>
              <strong>Jiangliu Wang</strong>,
              <a href="">Wei Li</a>
              <br>
              <em>Communications in Nonlinear Science and Numerical Simulation</em>, 2015
              <br>
              <a href="data/WangCOM2015.pdf">pdf</a> /
              <a href="data/WangCOM2015.bib">bibtex</a>
              <p></p>
              <p>
              An optimal interception strategy of the defender is provided with interpretations of its physical meaning, which depends on relative mobility of the intruder and defender.
              </p>
            </td>
          </tr>

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Thesis</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/cuhk.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/Thesis-Jiangliu-Wang.pdf">
              <papertitle>Self-Supervised Video Representation Learning</papertitle>
              </a>
              <br>
              <strong>Jiangliu Wang</strong>
              <br>
              September, 2020 
              <br>
              <a href="data/Thesis-Jiangliu-Wang.pdf">pdf</a> &nbsp/&nbsp
              <a href="https://drive.google.com/file/d/1_u6V4gQC-6JA_bFgku-iO9ENsmz55T0r/view?usp=sharing">slides</a>
              <p></p>
              
            </td>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Service</heading>
              <p>
              Reviewer of 
              <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>, 
              <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>, 
              <a href=" https://icml21ssl.github.io/">ICML 2021 Workshop on SSL</a>,
              <a href="http://sslneuips20.github.io">NeurIPS 2020 Workshop on SSL</a>,
              <a href="https://ewh.ieee.org/soc/ras/conf/fullysponsored/icra/ICRA2020/www.icra2020.org/index.html">ICRA 2020</a>,
              <a href="https://www.iros2019.org/">IROS 2019</a>,
              <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">T-NNLS</a>,
              <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=100">RAM</a>. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Page template from <a href="https://github.com/jonbarron/jonbarron_website">Jonathan T. Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
